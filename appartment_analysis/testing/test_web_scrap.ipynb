{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages used in this notebook\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import configparser\n",
    "\n",
    "# setting the starting url \n",
    "url_overview_k√∂ln = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln.73.0.0.1.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['wg-zimmer-in-Koeln-Holweide.7552060.html', 'wg-zimmer-in-Koeln-Bayenthal.11108555.html', 'wg-zimmer-in-Koeln-Nippes.11108870.html', 'wg-zimmer-in-Koeln-Buchforst.5777857.html', 'wg-zimmer-in-Koeln-Efferen-Huerth.11108852.html', 'wg-zimmer-in-Koeln-Nippes.11002623.html', 'wg-zimmer-in-Koeln-Lindenthal.10289233.html', 'wg-zimmer-in-Koeln-Lindenthal.10987669.html', 'wg-zimmer-in-Koeln-Braunsfeld.10444599.html', 'wg-zimmer-in-Koeln-Zollstock.11107635.html', 'wg-zimmer-in-Koeln-Ehrenfeld.8086704.html', 'wg-zimmer-in-Koeln-Ehrenfeld.6654704.html', 'wg-zimmer-in-Koeln.6196076.html', 'wg-zimmer-in-Koeln-Humboldt-Gremberg.11104860.html', 'wg-zimmer-in-Koeln.11108575.html', 'wg-zimmer-in-Koeln-Weiden.11108663.html', 'wg-zimmer-in-Koeln-Hoehenberg.11065928.html', 'wg-zimmer-in-Koeln-Lindenthal.11104584.html', 'wg-zimmer-in-Koeln-Neustadt-Sued.11108589.html', 'wg-zimmer-in-Koeln-Lindenthal.7308959.html']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "# Sends a GET request to the URL to retrieve its content; The Website tryes to redicrect the request to a captcha page, reloading solves the problem\n",
    "response = requests.get(url_overview_k√∂ln, allow_redirects=False)\n",
    "# assert response.status_code == 200\n",
    "print(response.status_code)\n",
    "# Parse results\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "target_class = \"ang_spalte_icons row_click\"\n",
    "elements = soup.find_all('td', class_=target_class)\n",
    "links=[]\n",
    "for element in elements:\n",
    "    links.append(element.find('a').get('href'))\n",
    "# Extracting all shared apartments\n",
    "#for link in soup.find_all('a'):\n",
    "#    print(link.get('href'))\n",
    "print(links)\n",
    "print(len(links))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "302 => Captcha -->nochmal probieren\n",
    "200 => Okay\n",
    "\n",
    "wnen die Klasse auf einer Seite nicht mehr gefunden werden kann, enth√§lt diese keine Angebote mehr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more elements found\n",
      "Base links: \n",
      "[]\n",
      "Anzahl der Base links:0\n",
      "Campaign links: \n",
      "[]\n",
      "Anzahl der Campaign links:0\n",
      "Pages: 0\n",
      "Failed: 0\n"
     ]
    }
   ],
   "source": [
    "page = 0\n",
    "failed_overview = 0\n",
    "base_links=[]\n",
    "campaign_links=[]\n",
    "\n",
    "# main class for the links\n",
    "target_class = \"truncate_title noprint\"\n",
    "\n",
    "# class for the campaign links\n",
    "campaign_class = \"campaign_click\"\n",
    "\n",
    "last_page = page\n",
    "cum_fails = 0\n",
    "while page <= 20:\n",
    "    # setting the url \n",
    "    url_overview_k√∂ln = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln.73.0.1.\"+str(page)+\".html\"\n",
    "\n",
    "    # Sends a GET request to the URL to retrieve its content; sometimes the Website tryes to redicrect the request to a captcha page, reloading solves the problem\n",
    "    response = requests.get(url_overview_k√∂ln, allow_redirects=False)\n",
    "    \n",
    "    # test response code\n",
    "    if response.status_code == 302 and failed_overview < 5:\n",
    "        # try again\n",
    "        failed_overview += 1 \n",
    "        cum_fails += 1\n",
    "        # if needed, add a sleep here\n",
    "        continue\n",
    "    elif failed_overview >= 5:\n",
    "        print(\"Failed 5 times in a row\")\n",
    "        break\n",
    "    \n",
    "    page += 1\n",
    "    failed_overview = 0\n",
    "\n",
    "    # Parse results\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extracting all shared apartments\n",
    "    elements = soup.find_all('h3', class_ = target_class)\n",
    "\n",
    "    if len(elements) == 0:\n",
    "        print(\"No more elements found\")\n",
    "        break\n",
    "\n",
    "    \n",
    "    for element in elements:\n",
    "        for appartment in element.find_all('a', class_ = campaign_class):\n",
    "            campaign_links.append(element.find('a').get('href'))\n",
    "        for appartment in element.find_all('a', class_=''):\n",
    "            base_links.append(element.find('a').get('href'))\n",
    "\n",
    "    # just for debugging\n",
    "    last_page = page -1\n",
    "\n",
    "\n",
    "# TODO: aufh√ºbschen und in Funktionen packen\n",
    "print(\"Base links: \")\n",
    "print(base_links)\n",
    "\n",
    "set_base_links = set(base_links)\n",
    "base_links = list(set_base_links)\n",
    "print(\"Anzahl der Base links:\" + str(len(base_links)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Campaign links: \" )\n",
    "print(campaign_links)\n",
    "\n",
    "set_campaign_links = set(campaign_links)\n",
    "campaign_links = list(set_campaign_links)\n",
    "print(\"Anzahl der Campaign links:\" + str(len(campaign_links)))\n",
    "print(\"Pages: \"+str(last_page))\n",
    "print(\"Failed: \"+str(cum_fails))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Information for different shared Appartments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nur verifizierte Unternehmen haben die Klasse \"campaign clicks\" --> sind auch unten als Werbung aufgef√ºhrt\n",
    "\n",
    "verfifizierte Personen nicht\n",
    "\n",
    "\n",
    "\n",
    "416 Ergebnisse sind okay. Erwartet h√§tten wir 420 -> ggf. Werbungen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove wrong links in the camoaign links (asset_id...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Size</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Extra Costs</th>\n",
       "      <th>Other Costs</th>\n",
       "      <th>Deposit</th>\n",
       "      <th>Redemption Agreement</th>\n",
       "      <th>Address</th>\n",
       "      <th>Available From</th>\n",
       "      <th>Available Till</th>\n",
       "      <th>Online Since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Link, Title, Size, Rent, Extra Costs, Other Costs, Deposit, Redemption Agreement, Address, Available From, Available Till, Online Since]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: f√ºr eine Einzelseite die Attribute bestimmen\n",
    "result_df = pd.DataFrame(columns=['Link', 'Title', 'Size', 'Rent', 'Extra Costs', 'Other Costs', 'Deposit', 'Redemption Agreement', 'Address', 'Available From', 'Available Till', 'Online Since'])\n",
    "\n",
    "# Testing\n",
    "test_counter = 0\n",
    "failed_app_acc = 0\n",
    "\n",
    "shared_app = 0\n",
    "\n",
    "while shared_app < len(base_links):\n",
    "    url_shared_app = \"https://www.wg-gesucht.de\" + str(base_links[shared_app]) \n",
    "    response = requests.get(url_shared_app, allow_redirects=False)\n",
    "    print(response.status_code)\n",
    "    # test response code\n",
    "    if response.status_code == 302 and failed_app_acc < 5:\n",
    "        # try again\n",
    "        failed_app_acc += 1 \n",
    "        cum_fails += 1\n",
    "        # if needed, add a sleep here\n",
    "        time.sleep(10)\n",
    "        continue\n",
    "    elif failed_app_acc >= 5:\n",
    "        raise Exception(\"Failed 5 times in a row\")\n",
    "\n",
    "    if response.status_code == 503:\n",
    "        print(\"Service Unavailable. Retrying in 15 seconds\")\n",
    "        time.sleep(15)\n",
    "        failed_app_acc += 1 \n",
    "        cum_fails += 1\n",
    "        continue\n",
    "\n",
    "    shared_app += 1\n",
    "    failed_app_acc = 0\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extracting the title\n",
    "    title = soup.find('h1', class_='headline headline-detailed-view-title').text\n",
    "    title = title.replace('\\n', '').strip()\n",
    "\n",
    "    # Extracting the size\n",
    "    size = soup.find('b', class_='key_fact_value').text\n",
    "    size = size.replace('\\n', '').strip()\n",
    "\n",
    "    # TODO: Adding the count of people in the flat\n",
    "    # TODO: Maybe Restructure the replacing of the \\n and strip to a function and do it in the df\n",
    "    # Extracting the cost panel\n",
    "    cost_panel = soup.find_all('div', class_='panel section_panel')[1]\n",
    "\n",
    "    rent = cost_panel.find_all('span', class_='section_panel_value')[0].text\n",
    "    rent = rent.replace('\\n', '').strip()\n",
    "\n",
    "    extra_costs = cost_panel.find_all('span', class_='section_panel_value')[1].text\n",
    "    extra_costs = extra_costs.replace('\\n', '').strip()\n",
    "\n",
    "    other_costs = cost_panel.find_all('span', class_='section_panel_value')[2].text\n",
    "    other_costs = other_costs.replace('\\n', '').strip()\n",
    "\n",
    "    deposit = cost_panel.find_all('span', class_='section_panel_value')[3].text\n",
    "    deposit = deposit.replace('\\n', '').strip()\n",
    "\n",
    "    redemption_agreement = cost_panel.find_all('span', class_='section_panel_value')[4].text\n",
    "    redemption_agreement = redemption_agreement.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "\n",
    "    # Address and Availability Panel\n",
    "    address_panel = soup.find_all('div', class_='panel section_panel')[2]\n",
    "\n",
    "    address = address_panel.find_all('span', class_='section_panel_detail')[0].text\n",
    "    address = ' '.join(address.split())\n",
    "\n",
    "    available_from = address_panel.find_all('span', class_='section_panel_value')[0].text\n",
    "    available_from = available_from.replace('\\n', '').strip()\n",
    "\n",
    "    # Sometimes the available till is not available, so we need to check if the second span is 'frei bis:' --> if not we need to set it to n.a.\n",
    "    if address_panel.find_all('span', class_='section_panel_detail')[2].text.strip() == 'frei bis:':\n",
    "        available_till = address_panel.find_all('span', class_='section_panel_value')[1].text\n",
    "        available_till = available_till.replace('\\n', '').strip()\n",
    "        online_since = address_panel.find_all('b', class_='noprint')[0].text\n",
    "        online_since = online_since.replace('\\n', '').strip()\n",
    "\n",
    "    else:\n",
    "        available_till = \"n.a.\"\n",
    "        online_since = address_panel.find_all('b', class_='noprint')[0].text\n",
    "        online_since = online_since.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "    input_set = {'Link': url_shared_app, 'Title': title, 'Size': size, 'Rent': rent, 'Extra Costs': extra_costs, 'Other Costs': other_costs, 'Deposit': deposit, 'Redemption Agreement': redemption_agreement, 'Address': address, 'Available From': available_from, 'Available Till': available_till, 'Online Since': online_since}\n",
    "    result_df = result_df._append(input_set, ignore_index=True)\n",
    "\n",
    "    # Testing\n",
    "    test_counter += 100\n",
    "    if test_counter == 5:\n",
    "        break \n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Online:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Size</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Extra Costs</th>\n",
       "      <th>Other Costs</th>\n",
       "      <th>Deposit</th>\n",
       "      <th>Redemption Agreement</th>\n",
       "      <th>Address</th>\n",
       "      <th>Available From</th>\n",
       "      <th>Available Till</th>\n",
       "      <th>Online Since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.wg-gesucht.de/wg-zimmer-in-Koeln-E...</td>\n",
       "      <td>Gro√ües WG-Zimmer in 2.5-Zimmer-Wohnung - Ehren...</td>\n",
       "      <td>20m¬≤</td>\n",
       "      <td>690‚Ç¨</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>1500‚Ç¨</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>Venloer str. xxx 50825 K√∂ln Ehrenfeld</td>\n",
       "      <td>10.07.2024</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>5 Minuten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  https://www.wg-gesucht.de/wg-zimmer-in-Koeln-E...   \n",
       "\n",
       "                                               Title  Size  Rent Extra Costs  \\\n",
       "0  Gro√ües WG-Zimmer in 2.5-Zimmer-Wohnung - Ehren...  20m¬≤  690‚Ç¨        n.a.   \n",
       "\n",
       "  Other Costs Deposit Redemption Agreement  \\\n",
       "0        n.a.   1500‚Ç¨                 n.a.   \n",
       "\n",
       "                                 Address Available From Available Till  \\\n",
       "0  Venloer str. xxx 50825 K√∂ln Ehrenfeld     10.07.2024           n.a.   \n",
       "\n",
       "  Online Since  \n",
       "0    5 Minuten  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test_df = pd.DataFrame()\n",
    "url_shared_app = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Ehrenfeld.10763679.html\" \n",
    "response = requests.get(url_shared_app, allow_redirects=False)\n",
    "print(response.status_code)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Extracting the title\n",
    "title = soup.find('h1', class_='headline headline-detailed-view-title').text\n",
    "title = title.replace('\\n', '').strip()\n",
    "\n",
    "# Extracting the size\n",
    "size = soup.find('b', class_='key_fact_value').text\n",
    "size = size.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Maybe Restructure the replacing of the \\n and strip to a function and do it in the df\n",
    "# Extracting the cost panel\n",
    "cost_panel = soup.find_all('div', class_='panel section_panel')[1]\n",
    "\n",
    "rent = cost_panel.find_all('span', class_='section_panel_value')[0].text\n",
    "rent = rent.replace('\\n', '').strip()\n",
    "\n",
    "extra_costs = cost_panel.find_all('span', class_='section_panel_value')[1].text\n",
    "extra_costs = extra_costs.replace('\\n', '').strip()\n",
    "\n",
    "other_costs = cost_panel.find_all('span', class_='section_panel_value')[2].text\n",
    "other_costs = other_costs.replace('\\n', '').strip()\n",
    "\n",
    "deposit = cost_panel.find_all('span', class_='section_panel_value')[3].text\n",
    "deposit = deposit.replace('\\n', '').strip()\n",
    "\n",
    "redemption_agreement = cost_panel.find_all('span', class_='section_panel_value')[4].text\n",
    "redemption_agreement = redemption_agreement.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "\n",
    "# Address and Availability Panel\n",
    "address_panel = soup.find_all('div', class_='panel section_panel')[2]\n",
    "\n",
    "address = address_panel.find_all('span', class_='section_panel_detail')[0].text\n",
    "address = ' '.join(address.split())\n",
    "\n",
    "available_from = address_panel.find_all('span', class_='section_panel_value')[0].text\n",
    "available_from = available_from.replace('\\n', '').strip()\n",
    "\n",
    "# Sometimes the available till is not available, so we need to check if the second span is 'frei bis:' --> if not we need to set it to n.a.\n",
    "if address_panel.find_all('span', class_='section_panel_detail')[2].text.strip() == 'frei bis:':\n",
    "    available_till = address_panel.find_all('span', class_='section_panel_value')[1].text\n",
    "    available_till = available_till.replace('\\n', '').strip()\n",
    "    online_since = address_panel.find_all('b', class_='noprint')[0].text\n",
    "    online_since = online_since.replace('\\n', '').strip()\n",
    "\n",
    "else:\n",
    "    available_till = \"n.a.\"\n",
    "    online_since = address_panel.find_all('b', class_='noprint')[0].text\n",
    "    online_since = online_since.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "input_set = {'Link': url_shared_app, 'Title': title, 'Size': size, 'Rent': rent, 'Extra Costs': extra_costs, 'Other Costs': other_costs, 'Deposit': deposit, 'Redemption Agreement': redemption_agreement, 'Address': address, 'Available From': available_from, 'Available Till': available_till, 'Online Since': online_since}\n",
    "result_test_df = result_test_df._append(input_set, ignore_index=True)\n",
    "\n",
    "\n",
    "print(address_panel.find_all('span', class_='section_panel_detail')[2].text.strip())\n",
    "result_test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wer lebt in der WG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Ehrenfeld.10763679.html\n",
      "2er WG (0w,1m,0d)\n",
      "Gr√∂√üe der WG: 2\n",
      "Gesamtanzahl Personen: 1\n",
      "Anzahl Frauen: 0\n",
      "Anzahl M√§nner: 1\n",
      "Anzahl Diverse: 0\n"
     ]
    }
   ],
   "source": [
    "print(str(result_test_df['Link'][0]))\n",
    "\n",
    "\n",
    "# TODO: Adding the count of people in the flat\n",
    "anz_ges = soup.find('span', class_='mr5')\n",
    "print(anz_ges['title'])\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_wg_info(wg_string):\n",
    "    # Regular expression to find the size of the WG (e.g., \"3er WG\")\n",
    "    wg_size_pattern = re.compile(r'(\\d+)er WG')\n",
    "    wg_size_match = wg_size_pattern.search(wg_string)\n",
    "    \n",
    "    if wg_size_match:\n",
    "        wg_size = int(wg_size_match.group(1))\n",
    "    else:\n",
    "        wg_size = None\n",
    "    \n",
    "    # Regular expression to find all groups (number and gender)\n",
    "    pattern = re.compile(r'(\\d+)([wmd])')\n",
    "    \n",
    "    # Find all matches in the input string\n",
    "    matches = pattern.findall(wg_string)\n",
    "    \n",
    "    total_people = 0\n",
    "    gender_counts = {'w': 0, 'm': 0, 'd': 0}\n",
    "    \n",
    "    for count, gender in matches:\n",
    "        count = int(count)\n",
    "        total_people += count\n",
    "        if gender in gender_counts:\n",
    "            gender_counts[gender] += count\n",
    "    \n",
    "    return wg_size, total_people, gender_counts\n",
    "\n",
    "wg_string = anz_ges['title']\n",
    "wg_size, total, genders = extract_wg_info(wg_string)\n",
    "print(f\"Gr√∂√üe der WG: {wg_size}\")\n",
    "print(f\"Gesamtanzahl Personen: {total}\")\n",
    "print(f\"Anzahl Frauen: {genders['w']}\")\n",
    "print(f\"Anzahl M√§nner: {genders['m']}\")\n",
    "print(f\"Anzahl Diverse: {genders['d']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WG Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wohnungsgr√∂√üe': 'Wohnungsgr√∂√üe: 65m¬≤', 'Zweck-WG': 0, 'Berufst√§tigen-WG': 1, 'gemischte-WG': 1, 'Sprache/n': 'Sprache/n: Deutsch, Englisch'}\n"
     ]
    }
   ],
   "source": [
    "detail_list = []\n",
    "detail_dic = {}\n",
    "details = soup.find_all('ul', class_='pl15 mb15')\n",
    "for detail in details:\n",
    "    spans = detail.find_all('span')\n",
    "    detail_list.extend(spans)\n",
    "details\n",
    "\n",
    "for span in detail_list:\n",
    "    span = span.text.replace('\\n', '').strip()\n",
    "    span = re.sub(r'\\s+', ' ', span)\n",
    "    \n",
    "    if 'rauchen' in span.lower():\n",
    "        detail_dic.update({'Rauchen': span}) \n",
    "    \n",
    "    if 'alter' in span.lower():\n",
    "        detail_dic.update({'Alter': span})\n",
    "    \n",
    "    if 'wohnungsgr√∂√üe' in span.lower():\n",
    "        detail_dic.update({'Wohnungsgr√∂√üe': span})\n",
    "    \n",
    "    if 'sprache/n' in span.lower():\n",
    "        detail_dic.update({'Sprache/n': span})\n",
    "    \n",
    "    if ('zweck-wg'  in span.lower()) or ('zweck wg' in span.lower()) or ('zweckgemeinschaft' in span.lower()):\n",
    "        detail_dic.update({'Zweck-WG': 1})\n",
    "\n",
    "    if ('frauen-wg' in span.lower()) or ('frauen wg' in span.lower()) or ('m√§dels wg' in span.lower()) or ('m√§dels-wg' in span.lower()):\n",
    "        detail_dic.update({'Frauen-WG': 1})\n",
    "    \n",
    "    if ('m√§nner-wg' in span.lower()) or ('m√§nner wg' in span.lower()) or ('jungs wg' in span.lower()) or ('jungs-wg' in span.lower()):\n",
    "        detail_dic.update({'M√§nner-WG': 1})\n",
    "    \n",
    "    if ('berufst√§tigen-wg' in span.lower()) or ('berufst√§tigen wg' in span.lower()) or ('berufst√§tige wg' in span.lower()) or ('berufst√§tige-wg' in span.lower()):\n",
    "        detail_dic.update({'Berufst√§tigen-WG': 1})\n",
    "    \n",
    "    if ('gemischte wg' in span.lower()) or ('gemischte-wg' in span.lower()):\n",
    "        detail_dic.update({'gemischte-WG': 1})\n",
    "\n",
    "    if ('studenten-wg' in span.lower()) or ('studenten wg' in span.lower()) or ('studentinnen wg' in span.lower()) or ('studentinnen-wg' in span.lower()):\n",
    "        detail_dic.update({'Studenten-WG': 1})\n",
    "    \n",
    "    if ('keine zweck-wg' in span.lower()) or ('keine zweck wg' in span.lower()) or ('keine zweckgemeinschaft' in span.lower()):\n",
    "        detail_dic.update({'Zweck-WG': 0})\n",
    "    \n",
    "    if ('verbindung' in span.lower()):\n",
    "        detail_dic.update({'Verbindung': 1})\n",
    "\n",
    "    if('azubi-wg' in span.lower()) or ('azubi wg' in span.lower()) or ('azubis wg' in span.lower()) or ('azubis-wg' in span.lower()):\n",
    "        detail_dic.update({'Azubi-WG': 1})\n",
    "    \n",
    "    if ('lgbtq' in span.lower()) or ('queer' in span.lower()):\n",
    "        detail_dic.update({'LGBTQ': 1})\n",
    "\n",
    "print(detail_dic)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gesucht wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geschlecht egal\n",
      "                                        \n",
      "                                        \n",
      "                                        \n",
      "                                        \n",
      "                                                                                                                                    zwischen 19 und 40 Jahren\n"
     ]
    }
   ],
   "source": [
    "headline = soup.find('h4', class_='headline pb0', string = re.compile(r'Gesucht wird:'))\n",
    "\n",
    "# Finde das n√§chste span-Element mit der Klasse \"section_panel_detail\" nach der √úberschrift\n",
    "if headline:\n",
    "    section_detail = headline.find_next('span', class_='section_panel_detail')\n",
    "    if section_detail:\n",
    "        # Extrahiere den Text und entferne unn√∂tige Leerzeichen\n",
    "        text = section_detail.get_text(strip=True)\n",
    "        print(text)\n",
    "    else:\n",
    "        print(\"Kein passendes span-Element gefunden.\")\n",
    "else:\n",
    "    print(\"Kein passendes h4-Element gefunden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angaben zum Objekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"utility_icons\">\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-city mdi-42px round_gray_background\"></span>\n",
       "<br><br/>\n",
       "\n",
       "                                                                                                                                                                                                                                                            Mehrfamilienhaus                                                                                                        </br></div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-office-building mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                    2. OG\n",
       "                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-bed-double-outline mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                    m√∂bliert                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-shower mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                                                        Dusche                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-wifi mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                    WLAN\n",
       "                                                                    </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-layers mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                                                        Parkett, Fliesen                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-bus mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                    2\n",
       "                                                                            Minuten\n",
       "                                                                        zu Fu√ü entfernt\n",
       "                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-plus-circle-outline mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "<span lang=\"de\">Waschmaschine</span>, Sp√ºlmaschine, Balkon, Fahrradkeller                                </div>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ang_z_objekt = soup.find('div', class_='utility_icons')\n",
    "ang_z_objekt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"utility_icons\">\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-city mdi-42px round_gray_background\"></span>\n",
      "<br><br/>\n",
      "\n",
      "                                                                                                                                                                                                                                                            Mehrfamilienhaus                                                                                                        </br></div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-office-building mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                    2. OG\n",
      "                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-bed-double-outline mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                    m√∂bliert                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-shower mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                                                        Dusche                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-wifi mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                    WLAN\n",
      "                                                                    </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-layers mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                                                        Parkett, Fliesen                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-bus mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                    2\n",
      "                                                                            Minuten\n",
      "                                                                        zu Fu√ü entfernt\n",
      "                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-plus-circle-outline mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "<span lang=\"de\">Waschmaschine</span>, Sp√ºlmaschine, Balkon, Fahrradkeller                                </div>\n",
      "</div>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teppich</th>\n",
       "      <th>Balkon</th>\n",
       "      <th>m√∂bliert</th>\n",
       "      <th>Waschmaschine</th>\n",
       "      <th>Dusche</th>\n",
       "      <th>Fliesen</th>\n",
       "      <th>2\\n                                                                            Minuten\\n                                                                        zu Fu√ü entfernt</th>\n",
       "      <th>Parkett</th>\n",
       "      <th>Fahrradkeller</th>\n",
       "      <th>WLAN</th>\n",
       "      <th>Mehrfamilienhaus</th>\n",
       "      <th>2. OG</th>\n",
       "      <th>Sp√ºlmaschine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Teppich  Balkon  m√∂bliert  Waschmaschine  Dusche  Fliesen  \\\n",
       "0      1.0     NaN       NaN            NaN     NaN      NaN   \n",
       "1      NaN     1.0       1.0            1.0     1.0      1.0   \n",
       "2      NaN     NaN       1.0            NaN     NaN      NaN   \n",
       "\n",
       "   2\\n                                                                            Minuten\\n                                                                        zu Fu√ü entfernt  \\\n",
       "0                                                NaN                                                                                                                                 \n",
       "1                                                1.0                                                                                                                                 \n",
       "2                                                NaN                                                                                                                                 \n",
       "\n",
       "   Parkett  Fahrradkeller  WLAN  Mehrfamilienhaus  2. OG  Sp√ºlmaschine  \n",
       "0      NaN            NaN   NaN               NaN    NaN           NaN  \n",
       "1      1.0            1.0   1.0               1.0    1.0           1.0  \n",
       "2      NaN            NaN   NaN               NaN    NaN           NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "def extract_features_from_html(html_data):\n",
    "    soup = BeautifulSoup(html_data, 'html.parser')\n",
    "    containers = soup.find_all('div', class_='text-center')\n",
    "\n",
    "    features = set()\n",
    "\n",
    "    for container in containers:\n",
    "        # Extrahiere den Text und bereinige ihn\n",
    "        text = container.get_text(strip=True)\n",
    "        # Splitte den Text in einzelne Features\n",
    "        split_text = [t.strip() for t in text.split(',')]\n",
    "        features.update(split_text)\n",
    "\n",
    "    return features\n",
    "\n",
    "def update_dataframe_with_features(html_data, df):\n",
    "    # Extrahiere alle Features aus dem HTML\n",
    "    new_features = extract_features_from_html(html_data)\n",
    "\n",
    "    # Erstelle ein Dictionary f√ºr die neue Zeile\n",
    "    new_row = {feature: 1 for feature in new_features}\n",
    "\n",
    "    # F√ºge alle fehlenden Spalten hinzu und setze sie auf 0\n",
    "    for feature in df.columns:\n",
    "        if feature not in new_row:\n",
    "            new_row[feature] = np.nan\n",
    "\n",
    "    # F√ºge die neue Zeile zum DataFrame hinzu\n",
    "    df = df._append(new_row, ignore_index=True)\n",
    "\n",
    "    # F√ºge fehlende Spalten zu allen anderen Zeilen hinzu und setze sie auf 0\n",
    "    for feature in new_row:\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = np.nan\n",
    "            df.loc[df.index != len(df) - 1, feature] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "# Beispielnutzung\n",
    "url_shared_app = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Altstadt-Nord.11062804.html\" \n",
    "response = requests.get(url_shared_app, allow_redirects=False)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "html_data_2 = soup.find('div', class_='utility_icons')\n",
    "\n",
    "url_shared_app = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Ehrenfeld.10763679.html\" \n",
    "response = requests.get(url_shared_app, allow_redirects=False)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "html_data_1 = soup.find('div', class_='utility_icons')\n",
    "print(html_data_1)\n",
    "# Vorhandener DataFrame mit einer Spalte \"Teppich\"\n",
    "df = pd.DataFrame({'Teppich': [1]})\n",
    "\n",
    "# Aktualisiere den DataFrame mit den neuen Features aus den ersten HTML-Daten\n",
    "df = update_dataframe_with_features(str(html_data_1), df)\n",
    "\n",
    "# Aktualisiere den DataFrame mit den neuen Features aus den zweiten HTML-Daten\n",
    "df = update_dataframe_with_features(str(html_data_2), df)\n",
    "\n",
    "df.head()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teppich</th>\n",
       "      <th>m√∂bliert</th>\n",
       "      <th>entf√§llt die Pflicht. F√ºr denkmalgesch√ºtzte H√§user und Geb√§ude mit weniger als 50 Quadratmetern Nutzfl√§che ist kein Energieausweis n√∂tig.Baujahr 1928</th>\n",
       "      <th>4. OG</th>\n",
       "      <th>Dusche</th>\n",
       "      <th>Waschmaschine</th>\n",
       "      <th>Fernw√§rme</th>\n",
       "      <th>teilm√∂bliert</th>\n",
       "      <th>√ñkostrom</th>\n",
       "      <th>schlechte Parkm√∂glichkeiten</th>\n",
       "      <th>...</th>\n",
       "      <th>Neubau</th>\n",
       "      <th>4\\n                                                                            Minuten\\n                                                                        zu Fu√ü entfernt</th>\n",
       "      <th>gute Parkm√∂glichkeiten</th>\n",
       "      <th>Haustiere erlaubt</th>\n",
       "      <th>Gasheizung</th>\n",
       "      <th>PVC</th>\n",
       "      <th>Aufzug</th>\n",
       "      <th>2. OG</th>\n",
       "      <th>Flatrate</th>\n",
       "      <th>Gartenmitbenutzung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Teppich  m√∂bliert  \\\n",
       "0      1.0       NaN   \n",
       "1      NaN       1.0   \n",
       "2      NaN       1.0   \n",
       "3      NaN       NaN   \n",
       "\n",
       "   entf√§llt die Pflicht. F√ºr denkmalgesch√ºtzte H√§user und Geb√§ude mit weniger als 50 Quadratmetern Nutzfl√§che ist kein Energieausweis n√∂tig.Baujahr 1928  \\\n",
       "0                                                NaN                                                                                                       \n",
       "1                                                1.0                                                                                                       \n",
       "2                                                NaN                                                                                                       \n",
       "3                                                NaN                                                                                                       \n",
       "\n",
       "   4. OG  Dusche  Waschmaschine  Fernw√§rme  teilm√∂bliert  √ñkostrom  \\\n",
       "0    NaN     NaN            NaN        NaN           NaN       NaN   \n",
       "1    1.0     1.0            1.0        1.0           1.0       1.0   \n",
       "2    NaN     NaN            NaN        NaN           NaN       NaN   \n",
       "3    NaN     NaN            NaN        NaN           NaN       NaN   \n",
       "\n",
       "   schlechte Parkm√∂glichkeiten  ...  Neubau  \\\n",
       "0                          NaN  ...     NaN   \n",
       "1                          1.0  ...     NaN   \n",
       "2                          NaN  ...     NaN   \n",
       "3                          NaN  ...     1.0   \n",
       "\n",
       "   4\\n                                                                            Minuten\\n                                                                        zu Fu√ü entfernt  \\\n",
       "0                                                NaN                                                                                                                                 \n",
       "1                                                NaN                                                                                                                                 \n",
       "2                                                NaN                                                                                                                                 \n",
       "3                                                1.0                                                                                                                                 \n",
       "\n",
       "   gute Parkm√∂glichkeiten  Haustiere erlaubt  Gasheizung  PVC  Aufzug  2. OG  \\\n",
       "0                     NaN                NaN         NaN  NaN     NaN    NaN   \n",
       "1                     NaN                NaN         NaN  NaN     NaN    NaN   \n",
       "2                     NaN                NaN         NaN  NaN     NaN    NaN   \n",
       "3                     1.0                1.0         1.0  1.0     1.0    1.0   \n",
       "\n",
       "   Flatrate  Gartenmitbenutzung  \n",
       "0       NaN                 NaN  \n",
       "1       NaN                 NaN  \n",
       "2       NaN                 NaN  \n",
       "3       1.0                 1.0  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_shared_app = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Nippes.3577779.html\" \n",
    "response = requests.get(url_shared_app, allow_redirects=False)\n",
    "soup3 = BeautifulSoup(response.text, 'html.parser')\n",
    "html_data_3 = soup3.find('div', class_='utility_icons')\n",
    "\n",
    "df = update_dataframe_with_features(str(html_data_3), df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zimmer: \n",
      "Hey Future Roomie! \n",
      "\n",
      " I've got an exciting offer ‚Äì a dazzling fully-furnished 20m¬≤ room with city registration in the heart of Ehrenfeld. \n",
      "\n",
      " üõå Room Details: \n",
      " Renting out one bedroom in a two bedroom apartment.  \n",
      " Room size: 20m¬≤ - Only for single person! \n",
      " Apartment size: 65m¬≤ \n",
      " Fully Furnished: Refrigerator, Washing Machine, Dishwasher, Oven, Airfryer, Sofa, Dining Table, Wardrobe, and more. Also, has a spacious keller.  \n",
      "\n",
      " üìç Location: Ehrenfeld, Venloer Str. G√ºrtel \n",
      " Cafes, restaurants, gym, super markets are just 2 to 5 minutes walk away. \n",
      " üí∞ Rent & Deposit: \n",
      " -Rent: ‚Ç¨700 per month - Warm \n",
      " -Deposit: ‚Ç¨1500 (Refundable) \n",
      " üìÖ Availability: \n",
      " -Ready to move-in from July 1st onward! \n",
      " -Long-term rental, because good times should last as long as possible.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m zimmer \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreitext_0\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordWrap section_freetext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZimmer: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(zimmer))\n\u001b[1;32m----> 4\u001b[0m lage \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreitext_1\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordWrap section_freetext display-none\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLage: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(lage))\n\u001b[0;32m      7\u001b[0m wg_leben \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreitext_2\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordWrap section_freetext display-none\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "zimmer = soup.find('div', id='freitext_0', class_=\"wordWrap section_freetext\").text.strip()\n",
    "print('Zimmer: \\n' + str(zimmer))\n",
    "\n",
    "lage = soup.find('div', id='freitext_1', class_=\"wordWrap section_freetext display-none\").text.strip()\n",
    "print('Lage: \\n' + str(lage))\n",
    "\n",
    "wg_leben = soup.find('div', id='freitext_2', class_=\"wordWrap section_freetext display-none\").text.strip()\n",
    "print('WG-Leben: \\n' + str(wg_leben))\n",
    "\n",
    "sonstiges = soup.find('div', id='freitext_3', class_=\"wordWrap section_freetext\")\n",
    "print('Sonstiges: \\n' + str(sonstiges))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ben√∂tigte Unterlagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bewerbermappe\n",
      "Ausweis/ID\n"
     ]
    }
   ],
   "source": [
    "headline = soup.find('h3', class_='headline section_panel_title', string = re.compile(r'Ben√∂tigte Unterlagen'))\n",
    "\n",
    "# Finde das n√§chste span-Element mit der Klasse \"section_panel_detail\" nach der √úberschrift\n",
    "if headline:\n",
    "    test = True\n",
    "    while test:\n",
    "        ben_Unt = headline.find_next('b', class_='font-12px text-decoration-underline')\n",
    "        if ben_Unt:\n",
    "            # Extrahiere den Text und entferne unn√∂tige Leerzeichen\n",
    "            text = ben_Unt.get_text(strip=True)\n",
    "            print(text)\n",
    "            headline = ben_Unt\n",
    "        else:\n",
    "            test = False\n",
    "    \n",
    "else:\n",
    "    print(\"Es werden keine Unterlagen ben√∂tigt.\")\n",
    "\n",
    "# TODO: itsmydata oder SCHUFA in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraperapi-Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'scraperapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m config\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal.ini\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the password\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m scraper_api_key \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscraperapi\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      6\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m'\u001b[39m: scraper_api_key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.wg-gesucht.de/wg-zimmer-in-Koeln-Agnesviertel.8024813.html\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      7\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://api.scraperapi.com\u001b[39m\u001b[38;5;124m'\u001b[39m, params\u001b[38;5;241m=\u001b[39mpayload)\n",
      "File \u001b[1;32mc:\\Users\\julia\\Programmieren\\Programmiersprachen\\Python_Anaconda\\Lib\\configparser.py:979\u001b[0m, in \u001b[0;36mRawConfigParser.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_section \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_section(key):\n\u001b[1;32m--> 979\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxies[key]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'scraperapi'"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('local.ini')\n",
    "\n",
    "# Extract the password\n",
    "scraper_api_key = config['scraperapi']['key'].strip()\n",
    "payload = {'api_key': scraper_api_key, 'url': \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Agnesviertel.8024813.html\"}\n",
    "r = requests.get('http://api.scraperapi.com', params=payload)\n",
    "print(r.text)\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['/wg-zimmer-in-Koeln-Belgisches-Viertel.7798828.html', '/wg-zimmer-in-Koeln-Lindenthal.9499007.html', '/wg-zimmer-in-Koeln-Kalk.11019524.html', '/wg-zimmer-in-Koeln.11016563.html', '/wg-zimmer-in-Koeln-Altstadt-Sued.10663667.html', '/wg-zimmer-in-Koeln.8861077.html', '/wg-zimmer-in-Koeln-Marienburg.3216416.html', '/wg-zimmer-in-Koeln-Weidenpesch.8751447.html', '/wg-zimmer-in-Koeln-Neustadt-Sued.4864977.html', '/wg-zimmer-in-Koeln-Vingst.11016308.html', '/wg-zimmer-in-Koeln-Neustadt-Sued.7764003.html', '/wg-zimmer-in-Koeln-Humboldt-Gremberg.9090325.html', '/wg-zimmer-in-Koeln-Leverkusen-Wiesdorf.8836353.html', '/wg-zimmer-in-Koeln-Ehrenfeld.8183185.html', '/wg-zimmer-in-Koeln-Altstadt-Sued.7022036.html', '/wg-zimmer-in-Koeln-Neuehrenfeld-Neu-Ossendorf.11017025.html', '/wg-zimmer-in-Koeln-Altstadt-Sued.10081212.html', '/wg-zimmer-in-Koeln-Neustadt-Sued.9119691.html', '/wg-zimmer-in-Koeln-Neustadt-Sued.11019677.html', '/wg-zimmer-in-Koeln-Altstadt-Sued.11019572.html']\n"
     ]
    }
   ],
   "source": [
    "class Scraper():\n",
    "    def __init__(self):\n",
    "        self.scraper_api_key = self.set_api_param()\n",
    "        self.non_spons_links = []\n",
    "\n",
    "    def set_api_param(self):\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('local.ini')\n",
    "        return config['scraperapi']['key'].strip()\n",
    "\n",
    "    def get_page_via_api(self, url):\n",
    "        payload = {'api_key': self.scraper_api_key, 'url': url}\n",
    "        response = requests.get('http://api.scraperapi.com', params=payload)\n",
    "        return response\n",
    "    \n",
    "    def get_page_direct(self, url):\n",
    "        response = requests.get(url, allow_redirects=False)\n",
    "        return response\n",
    "    \n",
    "    def collect_non_spons_links_from_response(self, response):\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        elements = soup.find_all('h3', class_ = \"truncate_title noprint\")\n",
    "        for element in elements:\n",
    "            # Filtering for the non sponsored appartments\n",
    "            for appartment in element.find_all('a', class_=''):\n",
    "                self.non_spons_links.append(element.find('a').get('href'))\n",
    "        return self.non_spons_links\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Testing the Scraper() \n",
    "test = Scraper()\n",
    "test_response = test.get_page_direct(\"https://www.wg-gesucht.de/wg-zimmer-in-Koeln.73.0.1.0.html\")\n",
    "print(test_response.status_code)\n",
    "test.collect_non_spons_links_from_response(test_response)\n",
    "print(test.non_spons_links)\n",
    "print(len(test.non_spons_links))\n",
    "\n",
    "# TODO: Error Handling for the direct request --> switchin to the api request\n",
    "# TODO: save to json, after each page --> to avoid data loss\n",
    "# TODO: Adding the sponsored appartments\n",
    "# TODO: Loading the data of the appartments\n",
    "# TODO: Add more attributes to the appartments\n",
    "# TODO: Add the data to a dataframe\n",
    "# TODO: write an output function to save the data\n",
    "# TODO: better commenting\n",
    "# TODO: new class for appartments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
