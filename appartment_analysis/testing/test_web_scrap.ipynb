{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages used in this notebook\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import configparser\n",
    "\n",
    "# setting the starting url \n",
    "url_overview_köln = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln.73.0.0.1.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['wg-zimmer-in-Koeln-Holweide.7552060.html', 'wg-zimmer-in-Koeln-Bayenthal.11108555.html', 'wg-zimmer-in-Koeln-Nippes.11108870.html', 'wg-zimmer-in-Koeln-Buchforst.5777857.html', 'wg-zimmer-in-Koeln-Efferen-Huerth.11108852.html', 'wg-zimmer-in-Koeln-Nippes.11002623.html', 'wg-zimmer-in-Koeln-Lindenthal.10289233.html', 'wg-zimmer-in-Koeln-Lindenthal.10987669.html', 'wg-zimmer-in-Koeln-Braunsfeld.10444599.html', 'wg-zimmer-in-Koeln-Zollstock.11107635.html', 'wg-zimmer-in-Koeln-Ehrenfeld.8086704.html', 'wg-zimmer-in-Koeln-Ehrenfeld.6654704.html', 'wg-zimmer-in-Koeln.6196076.html', 'wg-zimmer-in-Koeln-Humboldt-Gremberg.11104860.html', 'wg-zimmer-in-Koeln.11108575.html', 'wg-zimmer-in-Koeln-Weiden.11108663.html', 'wg-zimmer-in-Koeln-Hoehenberg.11065928.html', 'wg-zimmer-in-Koeln-Lindenthal.11104584.html', 'wg-zimmer-in-Koeln-Neustadt-Sued.11108589.html', 'wg-zimmer-in-Koeln-Lindenthal.7308959.html']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "# Sends a GET request to the URL to retrieve its content; The Website tryes to redicrect the request to a captcha page, reloading solves the problem\n",
    "response = requests.get(url_overview_köln, allow_redirects=False)\n",
    "# assert response.status_code == 200\n",
    "print(response.status_code)\n",
    "# Parse results\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "target_class = \"ang_spalte_icons row_click\"\n",
    "elements = soup.find_all('td', class_=target_class)\n",
    "links=[]\n",
    "for element in elements:\n",
    "    links.append(element.find('a').get('href'))\n",
    "# Extracting all shared apartments\n",
    "#for link in soup.find_all('a'):\n",
    "#    print(link.get('href'))\n",
    "print(links)\n",
    "print(len(links))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "302 => Captcha -->nochmal probieren\n",
    "200 => Okay\n",
    "\n",
    "wnen die Klasse auf einer Seite nicht mehr gefunden werden kann, enthält diese keine Angebote mehr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more elements found\n",
      "Base links: \n",
      "[]\n",
      "Anzahl der Base links:0\n",
      "Campaign links: \n",
      "[]\n",
      "Anzahl der Campaign links:0\n",
      "Pages: 0\n",
      "Failed: 0\n"
     ]
    }
   ],
   "source": [
    "page = 0\n",
    "failed_overview = 0\n",
    "base_links=[]\n",
    "campaign_links=[]\n",
    "\n",
    "# main class for the links\n",
    "target_class = \"truncate_title noprint\"\n",
    "\n",
    "# class for the campaign links\n",
    "campaign_class = \"campaign_click\"\n",
    "\n",
    "last_page = page\n",
    "cum_fails = 0\n",
    "while page <= 20:\n",
    "    # setting the url \n",
    "    url_overview_köln = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln.73.0.1.\"+str(page)+\".html\"\n",
    "\n",
    "    # Sends a GET request to the URL to retrieve its content; sometimes the Website tryes to redicrect the request to a captcha page, reloading solves the problem\n",
    "    response = requests.get(url_overview_köln, allow_redirects=False)\n",
    "    \n",
    "    # test response code\n",
    "    if response.status_code == 302 and failed_overview < 5:\n",
    "        # try again\n",
    "        failed_overview += 1 \n",
    "        cum_fails += 1\n",
    "        # if needed, add a sleep here\n",
    "        continue\n",
    "    elif failed_overview >= 5:\n",
    "        print(\"Failed 5 times in a row\")\n",
    "        break\n",
    "    \n",
    "    page += 1\n",
    "    failed_overview = 0\n",
    "\n",
    "    # Parse results\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extracting all shared apartments\n",
    "    elements = soup.find_all('h3', class_ = target_class)\n",
    "\n",
    "    if len(elements) == 0:\n",
    "        print(\"No more elements found\")\n",
    "        break\n",
    "\n",
    "    \n",
    "    for element in elements:\n",
    "        for appartment in element.find_all('a', class_ = campaign_class):\n",
    "            campaign_links.append(element.find('a').get('href'))\n",
    "        for appartment in element.find_all('a', class_=''):\n",
    "            base_links.append(element.find('a').get('href'))\n",
    "\n",
    "    # just for debugging\n",
    "    last_page = page -1\n",
    "\n",
    "\n",
    "# TODO: aufhübschen und in Funktionen packen\n",
    "print(\"Base links: \")\n",
    "print(base_links)\n",
    "\n",
    "set_base_links = set(base_links)\n",
    "base_links = list(set_base_links)\n",
    "print(\"Anzahl der Base links:\" + str(len(base_links)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Campaign links: \" )\n",
    "print(campaign_links)\n",
    "\n",
    "set_campaign_links = set(campaign_links)\n",
    "campaign_links = list(set_campaign_links)\n",
    "print(\"Anzahl der Campaign links:\" + str(len(campaign_links)))\n",
    "print(\"Pages: \"+str(last_page))\n",
    "print(\"Failed: \"+str(cum_fails))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Information for different shared Appartments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nur verifizierte Unternehmen haben die Klasse \"campaign clicks\" --> sind auch unten als Werbung aufgeführt\n",
    "\n",
    "verfifizierte Personen nicht\n",
    "\n",
    "\n",
    "\n",
    "416 Ergebnisse sind okay. Erwartet hätten wir 420 -> ggf. Werbungen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove wrong links in the camoaign links (asset_id...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Size</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Extra Costs</th>\n",
       "      <th>Other Costs</th>\n",
       "      <th>Deposit</th>\n",
       "      <th>Redemption Agreement</th>\n",
       "      <th>Address</th>\n",
       "      <th>Available From</th>\n",
       "      <th>Available Till</th>\n",
       "      <th>Online Since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Link, Title, Size, Rent, Extra Costs, Other Costs, Deposit, Redemption Agreement, Address, Available From, Available Till, Online Since]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: für eine Einzelseite die Attribute bestimmen\n",
    "result_df = pd.DataFrame(columns=['Link', 'Title', 'Size', 'Rent', 'Extra Costs', 'Other Costs', 'Deposit', 'Redemption Agreement', 'Address', 'Available From', 'Available Till', 'Online Since'])\n",
    "\n",
    "# Testing\n",
    "test_counter = 0\n",
    "failed_app_acc = 0\n",
    "\n",
    "shared_app = 0\n",
    "\n",
    "while shared_app < len(base_links):\n",
    "    url_shared_app = \"https://www.wg-gesucht.de\" + str(base_links[shared_app]) \n",
    "    response = requests.get(url_shared_app, allow_redirects=False)\n",
    "    print(response.status_code)\n",
    "    # test response code\n",
    "    if response.status_code == 302 and failed_app_acc < 5:\n",
    "        # try again\n",
    "        failed_app_acc += 1 \n",
    "        cum_fails += 1\n",
    "        # if needed, add a sleep here\n",
    "        time.sleep(10)\n",
    "        continue\n",
    "    elif failed_app_acc >= 5:\n",
    "        raise Exception(\"Failed 5 times in a row\")\n",
    "\n",
    "    if response.status_code == 503:\n",
    "        print(\"Service Unavailable. Retrying in 15 seconds\")\n",
    "        time.sleep(15)\n",
    "        failed_app_acc += 1 \n",
    "        cum_fails += 1\n",
    "        continue\n",
    "\n",
    "    shared_app += 1\n",
    "    failed_app_acc = 0\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extracting the title\n",
    "    title = soup.find('h1', class_='headline headline-detailed-view-title').text\n",
    "    title = title.replace('\\n', '').strip()\n",
    "\n",
    "    # Extracting the size\n",
    "    size = soup.find('b', class_='key_fact_value').text\n",
    "    size = size.replace('\\n', '').strip()\n",
    "\n",
    "    # TODO: Adding the count of people in the flat\n",
    "    # TODO: Maybe Restructure the replacing of the \\n and strip to a function and do it in the df\n",
    "    # Extracting the cost panel\n",
    "    cost_panel = soup.find_all('div', class_='panel section_panel')[1]\n",
    "\n",
    "    rent = cost_panel.find_all('span', class_='section_panel_value')[0].text\n",
    "    rent = rent.replace('\\n', '').strip()\n",
    "\n",
    "    extra_costs = cost_panel.find_all('span', class_='section_panel_value')[1].text\n",
    "    extra_costs = extra_costs.replace('\\n', '').strip()\n",
    "\n",
    "    other_costs = cost_panel.find_all('span', class_='section_panel_value')[2].text\n",
    "    other_costs = other_costs.replace('\\n', '').strip()\n",
    "\n",
    "    deposit = cost_panel.find_all('span', class_='section_panel_value')[3].text\n",
    "    deposit = deposit.replace('\\n', '').strip()\n",
    "\n",
    "    redemption_agreement = cost_panel.find_all('span', class_='section_panel_value')[4].text\n",
    "    redemption_agreement = redemption_agreement.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "\n",
    "    # Address and Availability Panel\n",
    "    address_panel = soup.find_all('div', class_='panel section_panel')[2]\n",
    "\n",
    "    address = address_panel.find_all('span', class_='section_panel_detail')[0].text\n",
    "    address = ' '.join(address.split())\n",
    "\n",
    "    available_from = address_panel.find_all('span', class_='section_panel_value')[0].text\n",
    "    available_from = available_from.replace('\\n', '').strip()\n",
    "\n",
    "    # Sometimes the available till is not available, so we need to check if the second span is 'frei bis:' --> if not we need to set it to n.a.\n",
    "    if address_panel.find_all('span', class_='section_panel_detail')[2].text.strip() == 'frei bis:':\n",
    "        available_till = address_panel.find_all('span', class_='section_panel_value')[1].text\n",
    "        available_till = available_till.replace('\\n', '').strip()\n",
    "        online_since = address_panel.find_all('b', class_='noprint')[0].text\n",
    "        online_since = online_since.replace('\\n', '').strip()\n",
    "\n",
    "    else:\n",
    "        available_till = \"n.a.\"\n",
    "        online_since = address_panel.find_all('b', class_='noprint')[0].text\n",
    "        online_since = online_since.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "    input_set = {'Link': url_shared_app, 'Title': title, 'Size': size, 'Rent': rent, 'Extra Costs': extra_costs, 'Other Costs': other_costs, 'Deposit': deposit, 'Redemption Agreement': redemption_agreement, 'Address': address, 'Available From': available_from, 'Available Till': available_till, 'Online Since': online_since}\n",
    "    result_df = result_df._append(input_set, ignore_index=True)\n",
    "\n",
    "    # Testing\n",
    "    test_counter += 100\n",
    "    if test_counter == 5:\n",
    "        break \n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Online:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Size</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Extra Costs</th>\n",
       "      <th>Other Costs</th>\n",
       "      <th>Deposit</th>\n",
       "      <th>Redemption Agreement</th>\n",
       "      <th>Address</th>\n",
       "      <th>Available From</th>\n",
       "      <th>Available Till</th>\n",
       "      <th>Online Since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.wg-gesucht.de/wg-zimmer-in-Koeln-E...</td>\n",
       "      <td>Großes WG-Zimmer in 2.5-Zimmer-Wohnung - Ehren...</td>\n",
       "      <td>20m²</td>\n",
       "      <td>690€</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>1500€</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>Venloer str. xxx 50825 Köln Ehrenfeld</td>\n",
       "      <td>10.07.2024</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>5 Minuten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  https://www.wg-gesucht.de/wg-zimmer-in-Koeln-E...   \n",
       "\n",
       "                                               Title  Size  Rent Extra Costs  \\\n",
       "0  Großes WG-Zimmer in 2.5-Zimmer-Wohnung - Ehren...  20m²  690€        n.a.   \n",
       "\n",
       "  Other Costs Deposit Redemption Agreement  \\\n",
       "0        n.a.   1500€                 n.a.   \n",
       "\n",
       "                                 Address Available From Available Till  \\\n",
       "0  Venloer str. xxx 50825 Köln Ehrenfeld     10.07.2024           n.a.   \n",
       "\n",
       "  Online Since  \n",
       "0    5 Minuten  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test_df = pd.DataFrame()\n",
    "url_shared_app = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Ehrenfeld.10763679.html\" \n",
    "response = requests.get(url_shared_app, allow_redirects=False)\n",
    "print(response.status_code)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Extracting the title\n",
    "title = soup.find('h1', class_='headline headline-detailed-view-title').text\n",
    "title = title.replace('\\n', '').strip()\n",
    "\n",
    "# Extracting the size\n",
    "size = soup.find('b', class_='key_fact_value').text\n",
    "size = size.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Maybe Restructure the replacing of the \\n and strip to a function and do it in the df\n",
    "# Extracting the cost panel\n",
    "cost_panel = soup.find_all('div', class_='panel section_panel')[1]\n",
    "\n",
    "rent = cost_panel.find_all('span', class_='section_panel_value')[0].text\n",
    "rent = rent.replace('\\n', '').strip()\n",
    "\n",
    "extra_costs = cost_panel.find_all('span', class_='section_panel_value')[1].text\n",
    "extra_costs = extra_costs.replace('\\n', '').strip()\n",
    "\n",
    "other_costs = cost_panel.find_all('span', class_='section_panel_value')[2].text\n",
    "other_costs = other_costs.replace('\\n', '').strip()\n",
    "\n",
    "deposit = cost_panel.find_all('span', class_='section_panel_value')[3].text\n",
    "deposit = deposit.replace('\\n', '').strip()\n",
    "\n",
    "redemption_agreement = cost_panel.find_all('span', class_='section_panel_value')[4].text\n",
    "redemption_agreement = redemption_agreement.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "\n",
    "# Address and Availability Panel\n",
    "address_panel = soup.find_all('div', class_='panel section_panel')[2]\n",
    "\n",
    "address = address_panel.find_all('span', class_='section_panel_detail')[0].text\n",
    "address = ' '.join(address.split())\n",
    "\n",
    "available_from = address_panel.find_all('span', class_='section_panel_value')[0].text\n",
    "available_from = available_from.replace('\\n', '').strip()\n",
    "\n",
    "# Sometimes the available till is not available, so we need to check if the second span is 'frei bis:' --> if not we need to set it to n.a.\n",
    "if address_panel.find_all('span', class_='section_panel_detail')[2].text.strip() == 'frei bis:':\n",
    "    available_till = address_panel.find_all('span', class_='section_panel_value')[1].text\n",
    "    available_till = available_till.replace('\\n', '').strip()\n",
    "    online_since = address_panel.find_all('b', class_='noprint')[0].text\n",
    "    online_since = online_since.replace('\\n', '').strip()\n",
    "\n",
    "else:\n",
    "    available_till = \"n.a.\"\n",
    "    online_since = address_panel.find_all('b', class_='noprint')[0].text\n",
    "    online_since = online_since.replace('\\n', '').strip()\n",
    "\n",
    "\n",
    "input_set = {'Link': url_shared_app, 'Title': title, 'Size': size, 'Rent': rent, 'Extra Costs': extra_costs, 'Other Costs': other_costs, 'Deposit': deposit, 'Redemption Agreement': redemption_agreement, 'Address': address, 'Available From': available_from, 'Available Till': available_till, 'Online Since': online_since}\n",
    "result_test_df = result_test_df._append(input_set, ignore_index=True)\n",
    "\n",
    "\n",
    "print(address_panel.find_all('span', class_='section_panel_detail')[2].text.strip())\n",
    "result_test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wer lebt in der WG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Ehrenfeld.10763679.html\n",
      "2er WG (0w,1m,0d)\n",
      "Größe der WG: 2\n",
      "Gesamtanzahl Personen: 1\n",
      "Anzahl Frauen: 0\n",
      "Anzahl Männer: 1\n",
      "Anzahl Diverse: 0\n"
     ]
    }
   ],
   "source": [
    "print(str(result_test_df['Link'][0]))\n",
    "\n",
    "\n",
    "# TODO: Adding the count of people in the flat\n",
    "anz_ges = soup.find('span', class_='mr5')\n",
    "print(anz_ges['title'])\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_wg_info(wg_string):\n",
    "    # Regular expression to find the size of the WG (e.g., \"3er WG\")\n",
    "    wg_size_pattern = re.compile(r'(\\d+)er WG')\n",
    "    wg_size_match = wg_size_pattern.search(wg_string)\n",
    "    \n",
    "    if wg_size_match:\n",
    "        wg_size = int(wg_size_match.group(1))\n",
    "    else:\n",
    "        wg_size = None\n",
    "    \n",
    "    # Regular expression to find all groups (number and gender)\n",
    "    pattern = re.compile(r'(\\d+)([wmd])')\n",
    "    \n",
    "    # Find all matches in the input string\n",
    "    matches = pattern.findall(wg_string)\n",
    "    \n",
    "    total_people = 0\n",
    "    gender_counts = {'w': 0, 'm': 0, 'd': 0}\n",
    "    \n",
    "    for count, gender in matches:\n",
    "        count = int(count)\n",
    "        total_people += count\n",
    "        if gender in gender_counts:\n",
    "            gender_counts[gender] += count\n",
    "    \n",
    "    return wg_size, total_people, gender_counts\n",
    "\n",
    "wg_string = anz_ges['title']\n",
    "wg_size, total, genders = extract_wg_info(wg_string)\n",
    "print(f\"Größe der WG: {wg_size}\")\n",
    "print(f\"Gesamtanzahl Personen: {total}\")\n",
    "print(f\"Anzahl Frauen: {genders['w']}\")\n",
    "print(f\"Anzahl Männer: {genders['m']}\")\n",
    "print(f\"Anzahl Diverse: {genders['d']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WG Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wohnungsgröße': 'Wohnungsgröße: 65m²', 'Zweck-WG': 0, 'Berufstätigen-WG': 1, 'gemischte-WG': 1, 'Sprache/n': 'Sprache/n: Deutsch, Englisch'}\n"
     ]
    }
   ],
   "source": [
    "detail_list = []\n",
    "detail_dic = {}\n",
    "details = soup.find_all('ul', class_='pl15 mb15')\n",
    "for detail in details:\n",
    "    spans = detail.find_all('span')\n",
    "    detail_list.extend(spans)\n",
    "details\n",
    "\n",
    "for span in detail_list:\n",
    "    span = span.text.replace('\\n', '').strip()\n",
    "    span = re.sub(r'\\s+', ' ', span)\n",
    "    \n",
    "    if 'rauchen' in span.lower():\n",
    "        detail_dic.update({'Rauchen': span}) \n",
    "    \n",
    "    if 'alter' in span.lower():\n",
    "        detail_dic.update({'Alter': span})\n",
    "    \n",
    "    if 'wohnungsgröße' in span.lower():\n",
    "        detail_dic.update({'Wohnungsgröße': span})\n",
    "    \n",
    "    if 'sprache/n' in span.lower():\n",
    "        detail_dic.update({'Sprache/n': span})\n",
    "    \n",
    "    if ('zweck-wg'  in span.lower()) or ('zweck wg' in span.lower()) or ('zweckgemeinschaft' in span.lower()):\n",
    "        detail_dic.update({'Zweck-WG': 1})\n",
    "\n",
    "    if ('frauen-wg' in span.lower()) or ('frauen wg' in span.lower()) or ('mädels wg' in span.lower()) or ('mädels-wg' in span.lower()):\n",
    "        detail_dic.update({'Frauen-WG': 1})\n",
    "    \n",
    "    if ('männer-wg' in span.lower()) or ('männer wg' in span.lower()) or ('jungs wg' in span.lower()) or ('jungs-wg' in span.lower()):\n",
    "        detail_dic.update({'Männer-WG': 1})\n",
    "    \n",
    "    if ('berufstätigen-wg' in span.lower()) or ('berufstätigen wg' in span.lower()) or ('berufstätige wg' in span.lower()) or ('berufstätige-wg' in span.lower()):\n",
    "        detail_dic.update({'Berufstätigen-WG': 1})\n",
    "    \n",
    "    if ('gemischte wg' in span.lower()) or ('gemischte-wg' in span.lower()):\n",
    "        detail_dic.update({'gemischte-WG': 1})\n",
    "\n",
    "    if ('studenten-wg' in span.lower()) or ('studenten wg' in span.lower()) or ('studentinnen wg' in span.lower()) or ('studentinnen-wg' in span.lower()):\n",
    "        detail_dic.update({'Studenten-WG': 1})\n",
    "    \n",
    "    if ('keine zweck-wg' in span.lower()) or ('keine zweck wg' in span.lower()) or ('keine zweckgemeinschaft' in span.lower()):\n",
    "        detail_dic.update({'Zweck-WG': 0})\n",
    "    \n",
    "    if ('verbindung' in span.lower()):\n",
    "        detail_dic.update({'Verbindung': 1})\n",
    "\n",
    "    if('azubi-wg' in span.lower()) or ('azubi wg' in span.lower()) or ('azubis wg' in span.lower()) or ('azubis-wg' in span.lower()):\n",
    "        detail_dic.update({'Azubi-WG': 1})\n",
    "    \n",
    "    if ('lgbtq' in span.lower()) or ('queer' in span.lower()):\n",
    "        detail_dic.update({'LGBTQ': 1})\n",
    "\n",
    "print(detail_dic)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gesucht wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geschlecht egal\n",
      "                                        \n",
      "                                        \n",
      "                                        \n",
      "                                        \n",
      "                                                                                                                                    zwischen 19 und 40 Jahren\n"
     ]
    }
   ],
   "source": [
    "headline = soup.find('h4', class_='headline pb0', string = re.compile(r'Gesucht wird:'))\n",
    "\n",
    "# Finde das nächste span-Element mit der Klasse \"section_panel_detail\" nach der Überschrift\n",
    "if headline:\n",
    "    section_detail = headline.find_next('span', class_='section_panel_detail')\n",
    "    if section_detail:\n",
    "        # Extrahiere den Text und entferne unnötige Leerzeichen\n",
    "        text = section_detail.get_text(strip=True)\n",
    "        print(text)\n",
    "    else:\n",
    "        print(\"Kein passendes span-Element gefunden.\")\n",
    "else:\n",
    "    print(\"Kein passendes h4-Element gefunden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angaben zum Objekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"utility_icons\">\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-city mdi-42px round_gray_background\"></span>\n",
       "<br><br/>\n",
       "\n",
       "                                                                                                                                                                                                                                                            Mehrfamilienhaus                                                                                                        </br></div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-office-building mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                    2. OG\n",
       "                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-bed-double-outline mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                    möbliert                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-shower mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                                                        Dusche                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-wifi mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                    WLAN\n",
       "                                                                    </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-layers mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                                                        Parkett, Fliesen                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-bus mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "\n",
       "                                    2\n",
       "                                                                            Minuten\n",
       "                                                                        zu Fuß entfernt\n",
       "                                </div>\n",
       "<div class=\"text-center\">\n",
       "<span class=\"mdi mdi-plus-circle-outline mdi-42px round_gray_background\"></span>\n",
       "<br/><br/>\n",
       "<span lang=\"de\">Waschmaschine</span>, Spülmaschine, Balkon, Fahrradkeller                                </div>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ang_z_objekt = soup.find('div', class_='utility_icons')\n",
    "ang_z_objekt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"utility_icons\">\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-city mdi-42px round_gray_background\"></span>\n",
      "<br><br/>\n",
      "\n",
      "                                                                                                                                                                                                                                                            Mehrfamilienhaus                                                                                                        </br></div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-office-building mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                    2. OG\n",
      "                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-bed-double-outline mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                    möbliert                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-shower mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                                                        Dusche                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-wifi mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                    WLAN\n",
      "                                                                    </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-layers mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                                                        Parkett, Fliesen                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-bus mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "\n",
      "                                    2\n",
      "                                                                            Minuten\n",
      "                                                                        zu Fuß entfernt\n",
      "                                </div>\n",
      "<div class=\"text-center\">\n",
      "<span class=\"mdi mdi-plus-circle-outline mdi-42px round_gray_background\"></span>\n",
      "<br/><br/>\n",
      "<span lang=\"de\">Waschmaschine</span>, Spülmaschine, Balkon, Fahrradkeller                                </div>\n",
      "</div>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teppich</th>\n",
       "      <th>Balkon</th>\n",
       "      <th>möbliert</th>\n",
       "      <th>Waschmaschine</th>\n",
       "      <th>Dusche</th>\n",
       "      <th>Fliesen</th>\n",
       "      <th>2\\n                                                                            Minuten\\n                                                                        zu Fuß entfernt</th>\n",
       "      <th>Parkett</th>\n",
       "      <th>Fahrradkeller</th>\n",
       "      <th>WLAN</th>\n",
       "      <th>Mehrfamilienhaus</th>\n",
       "      <th>2. OG</th>\n",
       "      <th>Spülmaschine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Teppich  Balkon  möbliert  Waschmaschine  Dusche  Fliesen  \\\n",
       "0      1.0     NaN       NaN            NaN     NaN      NaN   \n",
       "1      NaN     1.0       1.0            1.0     1.0      1.0   \n",
       "2      NaN     NaN       1.0            NaN     NaN      NaN   \n",
       "\n",
       "   2\\n                                                                            Minuten\\n                                                                        zu Fuß entfernt  \\\n",
       "0                                                NaN                                                                                                                                 \n",
       "1                                                1.0                                                                                                                                 \n",
       "2                                                NaN                                                                                                                                 \n",
       "\n",
       "   Parkett  Fahrradkeller  WLAN  Mehrfamilienhaus  2. OG  Spülmaschine  \n",
       "0      NaN            NaN   NaN               NaN    NaN           NaN  \n",
       "1      1.0            1.0   1.0               1.0    1.0           1.0  \n",
       "2      NaN            NaN   NaN               NaN    NaN           NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "def extract_features_from_html(html_data):\n",
    "    soup = BeautifulSoup(html_data, 'html.parser')\n",
    "    containers = soup.find_all('div', class_='text-center')\n",
    "\n",
    "    features = set()\n",
    "\n",
    "    for container in containers:\n",
    "        # Extrahiere den Text und bereinige ihn\n",
    "        text = container.get_text(strip=True)\n",
    "        # Splitte den Text in einzelne Features\n",
    "        split_text = [t.strip() for t in text.split(',')]\n",
    "        features.update(split_text)\n",
    "\n",
    "    return features\n",
    "\n",
    "def update_dataframe_with_features(html_data, df):\n",
    "    # Extrahiere alle Features aus dem HTML\n",
    "    new_features = extract_features_from_html(html_data)\n",
    "\n",
    "    # Erstelle ein Dictionary für die neue Zeile\n",
    "    new_row = {feature: 1 for feature in new_features}\n",
    "\n",
    "    # Füge alle fehlenden Spalten hinzu und setze sie auf 0\n",
    "    for feature in df.columns:\n",
    "        if feature not in new_row:\n",
    "            new_row[feature] = np.nan\n",
    "\n",
    "    # Füge die neue Zeile zum DataFrame hinzu\n",
    "    df = df._append(new_row, ignore_index=True)\n",
    "\n",
    "    # Füge fehlende Spalten zu allen anderen Zeilen hinzu und setze sie auf 0\n",
    "    for feature in new_row:\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = np.nan\n",
    "            df.loc[df.index != len(df) - 1, feature] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "# Beispielnutzung\n",
    "url_shared_app = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Altstadt-Nord.11062804.html\" \n",
    "response = requests.get(url_shared_app, allow_redirects=False)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "html_data_2 = soup.find('div', class_='utility_icons')\n",
    "\n",
    "url_shared_app = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Ehrenfeld.10763679.html\" \n",
    "response = requests.get(url_shared_app, allow_redirects=False)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "html_data_1 = soup.find('div', class_='utility_icons')\n",
    "print(html_data_1)\n",
    "# Vorhandener DataFrame mit einer Spalte \"Teppich\"\n",
    "df = pd.DataFrame({'Teppich': [1]})\n",
    "\n",
    "# Aktualisiere den DataFrame mit den neuen Features aus den ersten HTML-Daten\n",
    "df = update_dataframe_with_features(str(html_data_1), df)\n",
    "\n",
    "# Aktualisiere den DataFrame mit den neuen Features aus den zweiten HTML-Daten\n",
    "df = update_dataframe_with_features(str(html_data_2), df)\n",
    "\n",
    "df.head()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teppich</th>\n",
       "      <th>möbliert</th>\n",
       "      <th>entfällt die Pflicht. Für denkmalgeschützte Häuser und Gebäude mit weniger als 50 Quadratmetern Nutzfläche ist kein Energieausweis nötig.Baujahr 1928</th>\n",
       "      <th>4. OG</th>\n",
       "      <th>Dusche</th>\n",
       "      <th>Waschmaschine</th>\n",
       "      <th>Fernwärme</th>\n",
       "      <th>teilmöbliert</th>\n",
       "      <th>Ökostrom</th>\n",
       "      <th>schlechte Parkmöglichkeiten</th>\n",
       "      <th>...</th>\n",
       "      <th>Neubau</th>\n",
       "      <th>4\\n                                                                            Minuten\\n                                                                        zu Fuß entfernt</th>\n",
       "      <th>gute Parkmöglichkeiten</th>\n",
       "      <th>Haustiere erlaubt</th>\n",
       "      <th>Gasheizung</th>\n",
       "      <th>PVC</th>\n",
       "      <th>Aufzug</th>\n",
       "      <th>2. OG</th>\n",
       "      <th>Flatrate</th>\n",
       "      <th>Gartenmitbenutzung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Teppich  möbliert  \\\n",
       "0      1.0       NaN   \n",
       "1      NaN       1.0   \n",
       "2      NaN       1.0   \n",
       "3      NaN       NaN   \n",
       "\n",
       "   entfällt die Pflicht. Für denkmalgeschützte Häuser und Gebäude mit weniger als 50 Quadratmetern Nutzfläche ist kein Energieausweis nötig.Baujahr 1928  \\\n",
       "0                                                NaN                                                                                                       \n",
       "1                                                1.0                                                                                                       \n",
       "2                                                NaN                                                                                                       \n",
       "3                                                NaN                                                                                                       \n",
       "\n",
       "   4. OG  Dusche  Waschmaschine  Fernwärme  teilmöbliert  Ökostrom  \\\n",
       "0    NaN     NaN            NaN        NaN           NaN       NaN   \n",
       "1    1.0     1.0            1.0        1.0           1.0       1.0   \n",
       "2    NaN     NaN            NaN        NaN           NaN       NaN   \n",
       "3    NaN     NaN            NaN        NaN           NaN       NaN   \n",
       "\n",
       "   schlechte Parkmöglichkeiten  ...  Neubau  \\\n",
       "0                          NaN  ...     NaN   \n",
       "1                          1.0  ...     NaN   \n",
       "2                          NaN  ...     NaN   \n",
       "3                          NaN  ...     1.0   \n",
       "\n",
       "   4\\n                                                                            Minuten\\n                                                                        zu Fuß entfernt  \\\n",
       "0                                                NaN                                                                                                                                 \n",
       "1                                                NaN                                                                                                                                 \n",
       "2                                                NaN                                                                                                                                 \n",
       "3                                                1.0                                                                                                                                 \n",
       "\n",
       "   gute Parkmöglichkeiten  Haustiere erlaubt  Gasheizung  PVC  Aufzug  2. OG  \\\n",
       "0                     NaN                NaN         NaN  NaN     NaN    NaN   \n",
       "1                     NaN                NaN         NaN  NaN     NaN    NaN   \n",
       "2                     NaN                NaN         NaN  NaN     NaN    NaN   \n",
       "3                     1.0                1.0         1.0  1.0     1.0    1.0   \n",
       "\n",
       "   Flatrate  Gartenmitbenutzung  \n",
       "0       NaN                 NaN  \n",
       "1       NaN                 NaN  \n",
       "2       NaN                 NaN  \n",
       "3       1.0                 1.0  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_shared_app = \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Nippes.3577779.html\" \n",
    "response = requests.get(url_shared_app, allow_redirects=False)\n",
    "soup3 = BeautifulSoup(response.text, 'html.parser')\n",
    "html_data_3 = soup3.find('div', class_='utility_icons')\n",
    "\n",
    "df = update_dataframe_with_features(str(html_data_3), df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zimmer: \n",
      "Hey Future Roomie! \n",
      "\n",
      " I've got an exciting offer – a dazzling fully-furnished 20m² room with city registration in the heart of Ehrenfeld. \n",
      "\n",
      " 🛌 Room Details: \n",
      " Renting out one bedroom in a two bedroom apartment.  \n",
      " Room size: 20m² - Only for single person! \n",
      " Apartment size: 65m² \n",
      " Fully Furnished: Refrigerator, Washing Machine, Dishwasher, Oven, Airfryer, Sofa, Dining Table, Wardrobe, and more. Also, has a spacious keller.  \n",
      "\n",
      " 📍 Location: Ehrenfeld, Venloer Str. Gürtel \n",
      " Cafes, restaurants, gym, super markets are just 2 to 5 minutes walk away. \n",
      " 💰 Rent & Deposit: \n",
      " -Rent: €700 per month - Warm \n",
      " -Deposit: €1500 (Refundable) \n",
      " 📅 Availability: \n",
      " -Ready to move-in from July 1st onward! \n",
      " -Long-term rental, because good times should last as long as possible.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m zimmer \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreitext_0\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordWrap section_freetext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZimmer: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(zimmer))\n\u001b[1;32m----> 4\u001b[0m lage \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreitext_1\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordWrap section_freetext display-none\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLage: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(lage))\n\u001b[0;32m      7\u001b[0m wg_leben \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreitext_2\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordWrap section_freetext display-none\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "zimmer = soup.find('div', id='freitext_0', class_=\"wordWrap section_freetext\").text.strip()\n",
    "print('Zimmer: \\n' + str(zimmer))\n",
    "\n",
    "lage = soup.find('div', id='freitext_1', class_=\"wordWrap section_freetext display-none\").text.strip()\n",
    "print('Lage: \\n' + str(lage))\n",
    "\n",
    "wg_leben = soup.find('div', id='freitext_2', class_=\"wordWrap section_freetext display-none\").text.strip()\n",
    "print('WG-Leben: \\n' + str(wg_leben))\n",
    "\n",
    "sonstiges = soup.find('div', id='freitext_3', class_=\"wordWrap section_freetext\")\n",
    "print('Sonstiges: \\n' + str(sonstiges))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benötigte Unterlagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bewerbermappe\n",
      "Ausweis/ID\n"
     ]
    }
   ],
   "source": [
    "headline = soup.find('h3', class_='headline section_panel_title', string = re.compile(r'Benötigte Unterlagen'))\n",
    "\n",
    "# Finde das nächste span-Element mit der Klasse \"section_panel_detail\" nach der Überschrift\n",
    "if headline:\n",
    "    test = True\n",
    "    while test:\n",
    "        ben_Unt = headline.find_next('b', class_='font-12px text-decoration-underline')\n",
    "        if ben_Unt:\n",
    "            # Extrahiere den Text und entferne unnötige Leerzeichen\n",
    "            text = ben_Unt.get_text(strip=True)\n",
    "            print(text)\n",
    "            headline = ben_Unt\n",
    "        else:\n",
    "            test = False\n",
    "    \n",
    "else:\n",
    "    print(\"Es werden keine Unterlagen benötigt.\")\n",
    "\n",
    "# TODO: itsmydata oder SCHUFA in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraperapi-Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'scraperapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m config\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal.ini\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the password\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m scraper_api_key \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscraperapi\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      6\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m'\u001b[39m: scraper_api_key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.wg-gesucht.de/wg-zimmer-in-Koeln-Agnesviertel.8024813.html\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      7\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://api.scraperapi.com\u001b[39m\u001b[38;5;124m'\u001b[39m, params\u001b[38;5;241m=\u001b[39mpayload)\n",
      "File \u001b[1;32mc:\\Users\\julia\\Programmieren\\Programmiersprachen\\Python_Anaconda\\Lib\\configparser.py:979\u001b[0m, in \u001b[0;36mRawConfigParser.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_section \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_section(key):\n\u001b[1;32m--> 979\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxies[key]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'scraperapi'"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('local.ini')\n",
    "\n",
    "# Extract the password\n",
    "scraper_api_key = config['scraperapi']['key'].strip()\n",
    "payload = {'api_key': scraper_api_key, 'url': \"https://www.wg-gesucht.de/wg-zimmer-in-Koeln-Agnesviertel.8024813.html\"}\n",
    "r = requests.get('http://api.scraperapi.com', params=payload)\n",
    "print(r.text)\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['/wg-zimmer-in-Koeln-Belgisches-Viertel.7798828.html', '/wg-zimmer-in-Koeln-Lindenthal.9499007.html', '/wg-zimmer-in-Koeln-Kalk.11019524.html', '/wg-zimmer-in-Koeln.11016563.html', '/wg-zimmer-in-Koeln-Altstadt-Sued.10663667.html', '/wg-zimmer-in-Koeln.8861077.html', '/wg-zimmer-in-Koeln-Marienburg.3216416.html', '/wg-zimmer-in-Koeln-Weidenpesch.8751447.html', '/wg-zimmer-in-Koeln-Neustadt-Sued.4864977.html', '/wg-zimmer-in-Koeln-Vingst.11016308.html', '/wg-zimmer-in-Koeln-Neustadt-Sued.7764003.html', '/wg-zimmer-in-Koeln-Humboldt-Gremberg.9090325.html', '/wg-zimmer-in-Koeln-Leverkusen-Wiesdorf.8836353.html', '/wg-zimmer-in-Koeln-Ehrenfeld.8183185.html', '/wg-zimmer-in-Koeln-Altstadt-Sued.7022036.html', '/wg-zimmer-in-Koeln-Neuehrenfeld-Neu-Ossendorf.11017025.html', '/wg-zimmer-in-Koeln-Altstadt-Sued.10081212.html', '/wg-zimmer-in-Koeln-Neustadt-Sued.9119691.html', '/wg-zimmer-in-Koeln-Neustadt-Sued.11019677.html', '/wg-zimmer-in-Koeln-Altstadt-Sued.11019572.html']\n"
     ]
    }
   ],
   "source": [
    "class Scraper():\n",
    "    def __init__(self):\n",
    "        self.scraper_api_key = self.set_api_param()\n",
    "        self.non_spons_links = []\n",
    "\n",
    "    def set_api_param(self):\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('local.ini')\n",
    "        return config['scraperapi']['key'].strip()\n",
    "\n",
    "    def get_page_via_api(self, url):\n",
    "        payload = {'api_key': self.scraper_api_key, 'url': url}\n",
    "        response = requests.get('http://api.scraperapi.com', params=payload)\n",
    "        return response\n",
    "    \n",
    "    def get_page_direct(self, url):\n",
    "        response = requests.get(url, allow_redirects=False)\n",
    "        return response\n",
    "    \n",
    "    def collect_non_spons_links_from_response(self, response):\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        elements = soup.find_all('h3', class_ = \"truncate_title noprint\")\n",
    "        for element in elements:\n",
    "            # Filtering for the non sponsored appartments\n",
    "            for appartment in element.find_all('a', class_=''):\n",
    "                self.non_spons_links.append(element.find('a').get('href'))\n",
    "        return self.non_spons_links\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Testing the Scraper() \n",
    "test = Scraper()\n",
    "test_response = test.get_page_direct(\"https://www.wg-gesucht.de/wg-zimmer-in-Koeln.73.0.1.0.html\")\n",
    "print(test_response.status_code)\n",
    "test.collect_non_spons_links_from_response(test_response)\n",
    "print(test.non_spons_links)\n",
    "print(len(test.non_spons_links))\n",
    "\n",
    "# TODO: Error Handling for the direct request --> switchin to the api request\n",
    "# TODO: save to json, after each page --> to avoid data loss\n",
    "# TODO: Adding the sponsored appartments\n",
    "# TODO: Loading the data of the appartments\n",
    "# TODO: Add more attributes to the appartments\n",
    "# TODO: Add the data to a dataframe\n",
    "# TODO: write an output function to save the data\n",
    "# TODO: better commenting\n",
    "# TODO: new class for appartments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
